{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training with horovod\n",
    "Horovod is a distributed training framework based on MPI. Horovod is only available with TensorFlow version 1.12 or newer. You can find more details at [Horovod README](https://github.com/uber/horovod).\n",
    "\n",
    "To enable Horovod, we need to make small changes to our script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training script that support Horovod distributed training\n",
    "Create a copy of the script (training_script/cifar10_keras_sm.py, **not the pipe script**) and save it as training_script/cifar10_keras_dist.py.\n",
    "in:\n",
    "```python\n",
    "def main(args):\n",
    "```\n",
    "\n",
    "### Start horovod\n",
    "add horovod support using the following code:\n",
    "```python\n",
    "    import horovod.keras as hvd\n",
    "    hvd.init()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "    K.set_session(tf.Session(config=config))\n",
    "```\n",
    "\n",
    "### Configure callbacks\n",
    "add the following callbacks:\n",
    "```python\n",
    "    callbacks.append(hvd.callbacks.BroadcastGlobalVariablesCallback(0))\n",
    "    callbacks.append(hvd.callbacks.MetricAverageCallback())\n",
    "    callbacks.append(hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=5, verbose=1))\n",
    "```\n",
    "\n",
    "change the checkpointd and tensorboard callback to run only on `hvd.rank() == o` (You want only a single process the send logs)\n",
    "```python\n",
    "    if hvd.rank() == 0:\n",
    "        callbacks.append(ModelCheckpoint(args.output_dir + '/checkpoint-{epoch}.h5'))\n",
    "        callbacks.append(TensorBoard(log_dir=args.model_dir,update_freq='epoch'))\n",
    "```\n",
    "\n",
    "### Configure the optimizer\n",
    "in\n",
    "```python\n",
    "# Add hvd to the function. also add it in the function call\n",
    "def keras_model_fn(learning_rate, weight_decay, optimizer, momentum, hvd): \n",
    "```\n",
    "configure the horovod optimizer.\n",
    "Change `size=1` to `size=hvd.size()`  \n",
    "\n",
    "add \n",
    "```python\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "```\n",
    "before \n",
    "```python\n",
    " model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Distributed training\n",
    "To start a distributed training job with Horovod, configure the job distribution:\n",
    "```python\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': # Number of Horovod processes per host\n",
    "                        }\n",
    "                }\n",
    "```\n",
    "\n",
    "Run the same job using 2 ml.p3.2xlarge instances (processes_per_host:1).  \n",
    "add the distributions configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "# Change base_job_name to 'cifar10-dist' for console visibility\n",
    "estimator = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good job!**  \n",
    "You can now use SageMaker training jobs for distributed jobs.\n",
    "Before continuing to the next notebook, look at the distribution job metrics from CloudWatch and TensorBoard.  \n",
    "You can use TensorBoard to compare between the different jobs that you ran.\n",
    "Run TensorBoard with   \n",
    "`--logdir dist:dist_model_dir,pipe:pipe_model_dir,file:normal_job_model_dir`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
